{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Parse in Practice_NLP.txt, a synthetic note from an Electronic Health Record, and print out the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BWH ED Nursing Record and other paper documents are still available through scanned documents in LMR. Select Results Menu, select Links, and then BWH Inpt/ED/Day Surg Scanned Record. If you need further assistance, please contact the Help Desk at (617) 732-5927.\n",
      "\n",
      "The above is an example of a real header you might encounter within a note. This is some additional random text that is not relevant for our\n",
      "task at hand. \n",
      "\n",
      "\n",
      "The patient came in at around 11:00AM today. They were seen around 11:30 AM. Their primary complaint was ongoing issues with their memory. \n",
      "They have been seeing their PCP at MGH for 10 years. Their primary care physician noted about a year ago that the patient's memory was declining. \n",
      "They ran a cognitive test but did not find evidence of dementia. They have no family history of Alzheimer's. They called after their visit at \n",
      "3  PM, requesting a refill for their Metformin. \n",
      "\n",
      "Lab values: \n",
      "HBA1c 9.0\n",
      "TUC 204\n",
      "ABCDKFKS 3 \n",
      "\n",
      "It is recommended that the patient see a neurologist, as they have not done so yet. The subject denies MCI but it appears like they \n",
      "may have early stage dementia. The patient will continue their metformin and check back in with me in six weeks.\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Read Practice_NLP.txt file with open\n",
    "BWH_text=open(\"Practice_NLP.txt\",\"r\").read()\n",
    "\n",
    "# 1.2 Import spaCy and create object 'nlp'\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 1.3 Invoke nlp object on the text file to create a new doc file BWH_doc\n",
    "BWH_doc = nlp(BWH_text)\n",
    "\n",
    "print(BWH_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print out the first 5 sentences (use spacy’s processing for determining what a sentence is, hint: use .sent object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 --> The BWH ED Nursing Record and other paper documents are still available through scanned documents in LMR.\n",
      "2 --> Select Results Menu, select Links, and then BWH Inpt/ED/Day Surg Scanned Record.\n",
      "3 --> If you need further assistance, please contact the Help Desk at (617) 732-5927.\n",
      "\n",
      "\n",
      "4 --> The above is an example of a real header you might encounter within a note.\n",
      "5 --> This is some additional random text that is not relevant for our\n",
      "task at hand. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def head_n_sentences(doc_file, n):\n",
    "    \"\"\"Function to display first n sentences in a doc file\"\"\"\n",
    "    sent_num = 1\n",
    "    for senttext in list(doc_file.sents)[0:n]:\n",
    "        print(sent_num,\"-->\", senttext)\n",
    "        sent_num += 1\n",
    "\n",
    "\n",
    "head_n_sentences(doc_file = BWH_doc,n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Write a rule to extract only paragraphs: define here as 3 or more full English sentences with at least one line of whitespace separating them from the next element of text. Print the 2 paragraphs in this note out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitespaces located at index:  [56, 90, 188, 201]\n",
      "\n",
      "\n",
      "Number of paragraphs identified in the doc file : 2\n",
      "\n",
      "\n",
      "PARAGRAPH 1 --> The patient came in at around 11:00AM today . They were seen around 11:30 AM . Their primary complaint was ongoing issues with their memory . \n",
      " They have been seeing their PCP at MGH for 10 years . Their primary care physician noted about a year ago that the patient 's memory was declining . \n",
      " They ran a cognitive test but did not find evidence of dementia . They have no family history of Alzheimer 's . They called after their visit at \n",
      " 3   PM , requesting a refill for their Metformin . \n",
      "\n",
      "\n",
      "\n",
      "PARAGRAPH 2 --> It is recommended that the patient see a neurologist , as they have not done so yet . The subject denies MCI but it appears like they \n",
      " may have early stage dementia . The patient will continue their metformin and check back in with me in six weeks . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.1 This function 'find_duplicates_indice' returns the exact locations of an element within a list. \n",
    "#     In this case we wish to locate the position of whitespaces \\n\\n or \\n\\n\\n\n",
    "def find_duplicates_indice(input_list, item_to_locate):\n",
    "    \"Function to locate the indices of specific items in a list\"\n",
    "    return [indc for indc, x in enumerate(input_list) if x == item_to_locate]\n",
    "\n",
    "# 3.2 Append and sort the location of whitespaces in variable space_loc\n",
    "space_loc = (find_duplicates_indice(input_list=[i.orth_ for i in BWH_doc],\n",
    "                               item_to_locate=\"\\n\\n\")+\n",
    "             find_duplicates_indice(input_list=[i.orth_ for i in BWH_doc],\n",
    "                               item_to_locate=\"\\n\\n\\n\"))\n",
    "\n",
    "space_loc.sort()\n",
    "\n",
    "print(\"Whitespaces located at index: \",space_loc)\n",
    "\n",
    "\n",
    "# 3.2 Segregate sentences in the doc file using the index 'space_loc', stored in list 'required_list'\n",
    "required_list=[]\n",
    "\n",
    "for i in np.arange(0,len(space_loc)):\n",
    "    if   (i< len(space_loc)-1):\n",
    "        required_list.append(\" \".join([i.orth_ for i in BWH_doc][space_loc[i]:space_loc[i+1]]).strip())\n",
    "    elif (i==len(space_loc)-1):\n",
    "        required_list.append(\" \".join([i.orth_ for i in BWH_doc][space_loc[i]:]).strip())\n",
    "\n",
    "        \n",
    "# 3.3 Eliminate sentences from the above 'required_list' if they have less than 3 periods in their paragraphs        \n",
    "for i in required_list:\n",
    "    if i.count(\".\")<3:\n",
    "        required_list.pop(required_list.index(i))\n",
    "        \n",
    "print(\"\\n\\nNumber of paragraphs identified in the doc file :\", len(required_list))\n",
    "\n",
    "\n",
    "# 3.4 Print all paragraphs \n",
    "for i in required_list:\n",
    "    print(\"\\n\\nPARAGRAPH\",\n",
    "          required_list.index(i)+1,\"-->\",\n",
    "          i,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Build a list of negative words (no, not, etc.) you would generally expect to see in everyday English (or that you see in the text). Turn this into a regular expression using re.compile. How many sentences have a negative word in them? Print them along with the index of the sentence containing the negative in the original document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sent_index</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>This is some additional random text that is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>They ran a cognitive test but did not find evi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>They have no family history of Alzheimer's.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>It is recommended that the patient see a neuro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sent_index                                               Text\n",
       "0           4  This is some additional random text that is no...\n",
       "1          10  They ran a cognitive test but did not find evi...\n",
       "2          11        They have no family history of Alzheimer's.\n",
       "3          17  It is recommended that the patient see a neuro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1 Import in-buit library 're' for regular expressions\n",
    "import re\n",
    "\n",
    "\n",
    "# 4.2 Build a list of all possible negative words\n",
    "words_negative = [\"not\",\"no\",\"nothing\",\"none\",\"never\",\"neither\"]\n",
    "\n",
    "\n",
    "# 4.3 Convert the above list to regular expression using re.compile()\n",
    "words_negative_regex_compiled = re.compile(r'\\b|'.join(words_negative))\n",
    "\n",
    "\n",
    "# 4.4 Print the sentences containing the negative keywords along with the index in the original document\n",
    "def disp_sent_with_keyword_list(doc_file, text_file, regex_compiled_list):\n",
    "    \"\"\"Function to display lines containing specific keywords\"\"\"\n",
    "    listed_doc = [str(lines).strip() for lines in list(doc_file.sents)]\n",
    "    list_of_keywords = [kw.center(len(kw)+2) for kw in list(set(regex_compiled_list.findall(text_file)))]\n",
    "    index=[]\n",
    "    text=[]\n",
    "    for sent in listed_doc:\n",
    "        ind_no = listed_doc.index(sent)\n",
    "        for kwds in list_of_keywords:\n",
    "            if kwds in sent:\n",
    "                index.append(ind_no)\n",
    "                text.append(sent)\n",
    "                \n",
    "    return pd.DataFrame({\"Sent_index\":index,\"Text\":text})\n",
    "                \n",
    "                \n",
    "\n",
    "disp_sent_with_keyword_list(doc_file  = BWH_doc,\n",
    "                            text_file = BWH_text,\n",
    "                            regex_compiled_list = words_negative_regex_compiled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, there are 4 sentences that contain at least 1 negative word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Get all negating dependencies using spacy’s dependency parser (token.dep_ = = ‘neg’) and print them. Which negative words did this miss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Dependancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Token Dependancy\n",
       "0   not        neg\n",
       "1   not        neg\n",
       "2   not        neg"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([(token,token.dep_) for token in BWH_doc if (token.dep_==\"neg\")],\n",
    "             columns=[\"Token\",\"Dependancy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the above parser has missed the token 'no' in the doc file which is also a negating dependancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Visualize the full note dependency using displacy’s visualizer. What is the dependency parse of a negative word (for example, “They have no family history of Alzheimer&#39;s”) that was missed in the previous step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"dfc47811399f4e67bc365ad0d4c675ae-0\" class=\"displacy\" width=\"1450\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Source Sans Pro; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">They</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">have</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">no</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">family</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">history</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Alzheimer</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">'s.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dfc47811399f4e67bc365ad0d4c675ae-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dfc47811399f4e67bc365ad0d4c675ae-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dfc47811399f4e67bc365ad0d4c675ae-0-1\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dfc47811399f4e67bc365ad0d4c675ae-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dfc47811399f4e67bc365ad0d4c675ae-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dfc47811399f4e67bc365ad0d4c675ae-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dfc47811399f4e67bc365ad0d4c675ae-0-3\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dfc47811399f4e67bc365ad0d4c675ae-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,266.5 L758.0,254.5 742.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dfc47811399f4e67bc365ad0d4c675ae-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dfc47811399f4e67bc365ad0d4c675ae-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dfc47811399f4e67bc365ad0d4c675ae-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dfc47811399f4e67bc365ad0d4c675ae-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-dfc47811399f4e67bc365ad0d4c675ae-0-6\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-dfc47811399f4e67bc365ad0d4c675ae-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1265.0,266.5 L1273.0,254.5 1257.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(docs=list(BWH_doc.sents)[11],\n",
    "                style=\"dep\",\n",
    "                jupyter=True,\n",
    "                options={\"font\": \"Source Sans Pro\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'determiner'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"DET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the dependancy parse of the negative word 'no' is a determiner for the word 'history'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Remove all sentences with negatives defined in your rule from step 4 and print out the final text object with these sentences removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 10, 11, 17]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(disp_sent_with_keyword_list(doc_file  = BWH_doc,\n",
    "                            text_file = BWH_text,\n",
    "                            regex_compiled_list = words_negative_regex_compiled)[\"Sent_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The BWH ED Nursing Record and other paper documents are still available through scanned documents in LMR.Select Results Menu, select Links, and then BWH Inpt/ED/Day Surg Scanned Record.If you need further assistance, please contact the Help Desk at (617) 732-5927.\n",
       "\n",
       "The above is an example of a real header you might encounter within a note.The patient came in at around 11:00AM today.They were seen around 11:30 AM.Their primary complaint was ongoing issues with their memory. \n",
       "They have been seeing their PCP at MGH for 10 years.Their primary care physician noted about a year ago that the patient's memory was declining. \n",
       "They called after their visit at \n",
       "3  PM, requesting a refill for their Metformin. \n",
       "\n",
       "Lab values: \n",
       "HBA1c 9.0\n",
       "TUC 204\n",
       "ABCDKFKS 3 \n",
       "\n",
       "The subject denies MCI but it appears like they \n",
       "may have early stage dementia.The patient will continue their metformin and check back in with me in six weeks."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_doc_file_using_index_list(doc_file, drop_index_list):\n",
    "    \"Function to eliminate lines from doc file using list of user specified indices\"\n",
    "    cleaned_file=\"\"\n",
    "    for i in list(doc_file.sents):\n",
    "        if list(doc_file.sents).index(i) not in drop_index_list:\n",
    "            cleaned_file=str(cleaned_file)+str(i)\n",
    "    return nlp(cleaned_file)\n",
    "\n",
    "\n",
    "\n",
    "clean_doc_file_using_index_list(doc_file=BWH_doc, \n",
    "                                drop_index_list=[4,10,11,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
